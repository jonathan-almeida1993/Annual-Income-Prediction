#!/usr/bin/python3
import json

#open file for reading data
file = open("income-data/income.train.txt","r");

json_file = open("FEATURE_VALUES.json");
dict = json.loads(json_file.read());
#the above dictionary has the following keys:
#'target', 'race', 'marital_status', 'workclass', 'occupation', 'sex', 'age', 'country', 'education', 'hours'

#make some changes to the dictionary of unique values
#ages range from 15 to 100
dict["age"] = list(range(15, 101));
#hours range from 1 to 100
dict["hours"] = list(range(1,101));
#print("FEATURE_VALUES::")
#print(dict)

#calculate the no. of dimensions in the resulting binary feature vector
no_of_dimensions = len(dict["age"])+len(dict["workclass"])+len(dict["education"])+len(dict["marital_status"])\
+len(dict["occupation"])+len(dict["race"])+len(dict["sex"])+len(dict["hours"])+len(dict["country"]) +1;
print("No of dimension = %d"%no_of_dimensions);

#basic Perceptron implementation
def perceptron(epochs):
	"""This function is the implementation of the basic Perceptron algorithm.
	It accepts the data set indicated by the file parameter, and the epochs. 
	The weight vector is maintained as a list and is initialized to zero.
	Once a single example is read from the file, it is converted into its
	feature vector. The weight vector and the feature vector have the same
	number of dimensions."""
	weight_vector = [0]*no_of_dimensions;
	bias = 0;
	for var in range(epochs):
		for line in file:
			#Get the feature vector and the label of the current example
			feature_vector, true_label = process_input(line);
			
			#compute the dot product between the feature vector and the weight vector
			dot_product = 0;
			for component in range(no_of_dimensions):
				dot_product += (weight_vector[component]*feature_vector[component]);
			
			#compute activation
			activation = dot_product+bias;
			if (activation*true_label)<=0:
				for component in range(no_of_dimensions):
					weight_vector[component] += (true_label*feature_vector[component]);
				bias += true_label;
			print("\nLine = %s"%(line.strip()))
			print("\nWEIGHT VECTOR = %s"%(weight_vector))
	return weight_vector,bias;

def perceptron_test(weight_vector_final,bias_final):
	"""This function tests the weight vector and the bias generated by 
	the perceptron algorithm on the test data."""
	test_data = open("income-data/income.dev.txt","r");
	for line in test_data:
			#Get the feature vector for the current example
			feature_vector, ignore_this = process_input(line);
			
			#compute the dot product between the feature vector and the weight vector
			dot_product = 0;
			for component in range(no_of_dimensions):
				dot_product += (weight_vector_final[component]*feature_vector[component]);
			
			#compute activation
			activation = dot_product+bias_final;
			print("\nCURRENT INPUT -> %s"%(line.strip()));
			if(activation>0):
				print(">50K");
			else:
				print("<=50K");
	test_data.close();
	return

def process_input(example):
	"""This function accepts the current example indicated by the 
	example parameter,	and converts it into its corresponding feature vector. 
	It also outputs the true label in binary. The sequence of the features in
	example is as follows: Age, Workclass, Education, Marital_Status, Occupation, 
	Race, Sex, Hours, Country, Target."""

	#print("INPUT LINE::");
	#print(example)
	#print("\n")
	#create binary feature vectors and intialize them to 0
	age=[0]*len(dict["age"]);
	workclass=[0]*len(dict["workclass"]);
	education=[0]*len(dict["education"]);
	marital_status=[0]*len(dict["marital_status"]);
	occupation=[0]*len(dict["occupation"]);
	race=[0]*len(dict["race"]);
	sex=[0]*len(dict["sex"]);
	hours=[0]*len(dict["hours"]);
	country=[0]*len(dict["country"]);
	true_label=-1;

	#set features found in the example to 1
	feature = example.split(",");
	age[dict["age"].index(int(feature[0].strip()))] = 1;
	#print("AGE")
	#print(dict["age"])
	#print(age)
	#print("\n")
	workclass[dict["workclass"].index(feature[1].strip())] = 1;
	#print("WORKCLASS")
	#print(dict["workclass"])
	#print(workclass)
	#print("\n")
	education[dict["education"].index(feature[2].strip())] = 1;
	#print("EDUCATION")
	#print(dict["education"])
	#print(education)
	#print("\n")
	marital_status[dict["marital_status"].index(feature[3].strip())] = 1;
	#print("MARITAL_STATUS")
	#print(dict["marital_status"])
	#print(marital_status)
	#print("\n")
	occupation[dict["occupation"].index(feature[4].strip())] = 1;
	#print("OCCUPATION")
	#print(dict["occupation"])
	#print(occupation)
	#print("\n")	
	race[dict["race"].index(feature[5].strip())] = 1;
	#print("RACE")
	#print(dict["race"])
	#print(race)
	#print("\n")	
	sex[dict["sex"].index(feature[6].strip())] = 1;
	#print("SEX")
	#print(dict["sex"])
	#print(sex)
	#print("\n")	
	hours[dict["hours"].index(int(feature[7].strip()))] = 1;
	#print("HOURS")
	#print(dict["hours"])
	#print(hours)
	#print("\n")	
	country[dict["country"].index(feature[8].strip())] = 1;
	#print("COUNTRY")
	#print(dict["country"])
	#print(country)
	#print("\n")
	if feature[9] == ">50K":
		true_label = 1; 
	
	#combine all the individual binary feature lists into a binary feature vector
	feature_vector = age + workclass + education + marital_status + occupation + race + sex + hours + country;
	#add a bias dimension
	feature_vector.append(1);
	return feature_vector,true_label;



def test_it():

	# print("\nTraining on the data set...")
	# weight_vector_final,bias_final = perceptron(1);
	# print(weight_vector_final)
	# print(bias_final)
	#print("\nTesting on the data set...")
	#perceptron_test(weight_vector_final,bias_final);
	file.close();
	json_file.close();


test_it()